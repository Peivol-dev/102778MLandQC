{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Quantum Computers\n",
    "\n",
    "### UD2. Classical Neural Networks Exercises\n",
    "\n",
    "##### Student: \tPablo Flores Millan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Single-layer Perceptron\n",
    "\n",
    "**Let X = [[0, -2],[1, 4],[2, 1],[4, -4],[4, -3],[5, 6],[6, 2]],  y = [1, -1, 1, 1, -1, 1, -1] be the data matrix and the vector of actual labels for a classification problem, respectively.**\n",
    "\n",
    "1. **Represent the feature vectors in a Cartesian plane. Use different shapes to differentiate among classes: little circles for vectors with “-1” label and plus signs for vectors with “1” label.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Defining vectors X and y provided in the question\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Defining vectors X and y provided in the question\n",
    "X = np.array([[0, -2], [1, 4], [2, 1], [4, -4], [4, -3], [5, 6], [6, 2]])\n",
    "y = np.array([1,-1,1,1,-1,1,-1])\n",
    "\n",
    "# Extracting the x and y coordinates for the X vectors (Xvect)\n",
    "x1 = X[:, 0]  # x-coordinates\n",
    "x2 = X[:, 1]  # y-coordinates\n",
    "\n",
    "# Distinguishing through the labels provided by the y vector (yvect)\n",
    "for i, point in enumerate(X):\n",
    "    plt.annotate(f'({point[0]}, {point[1]})', (x1[i], x2[i]), textcoords=\"offset points\", xytext=(0,4), ha='center')\n",
    "    if y[i] == 1:\n",
    "        plt.scatter(x1[i], x2[i], color='red', s=150, marker='+')\n",
    "    else:\n",
    "        plt.scatter(x1[i], x2[i], color='blue', s=50, marker='o')\n",
    "\n",
    "# Plot title and labels\n",
    "plt.title('Cartesian Plane Representation of X Vectors')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **To separate the data we can use a single-layer perceptron with three neurons (taking the first one as the threshold). Take w0 = [-7,2,1] as an initial weight vector. Draw the straight line that corresponds to this vector, in the same plot you made the previous question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The initial weights vector w0 provided in the question is:\n",
    "w_0 = np.array([-7, 2, 1])\n",
    "\n",
    "# In order to implement the Single-layer Perceptron algorithm, we need to calculate the decision boundary equation.\n",
    "# In this case, taking Z=[1,z1,z2] as the variable vector (because the first component is the threshold), \n",
    "# we obtain the equation: \n",
    "# \n",
    "#                                                   w0*Z = 0.\n",
    "\n",
    "\n",
    "# In other words, the decision boundary equation is: w0 + w1*z1 + w2*z2 = 0\n",
    "# We can rewrite the equation as: z2 = -w0[1]*z1 - w0[0]\n",
    "\n",
    "# Due to it, we define the decision boundary equation as follows:\n",
    "x1_vals = np.linspace(min(X[:, 0]) - 1, max(X[:, 0]) + 1, 100)\n",
    "x2_vals = -w_0[1] * x1_vals - w_0[0]  # Calculate x2 using the line equation\n",
    "\n",
    "# The previously defined plot:\n",
    "for i, point in enumerate(X):\n",
    "    plt.annotate(f'({point[0]}, {point[1]})', (x1[i], x2[i]), textcoords=\"offset points\", xytext=(0,4), ha='center')\n",
    "    if y[i] == 1:\n",
    "        plt.scatter(x1[i], x2[i], color='red', s=150, marker='+')\n",
    "    else:\n",
    "        plt.scatter(x1[i], x2[i], color='blue', s=50, marker='o')\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.plot(x1_vals, x2_vals, label='Decision Boundary', color='black', linestyle='--')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Cartesian Plane Representation')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Execute the gradient descent perceptron algorithm for these data and write a table of the weights for subsequent learning epochs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column of 1s to X for the bias term (w0)\n",
    "X_bias = np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "# Initialize the weight vector with arbitrary values (e.g., zeros or small random values)\n",
    "w = np.array([0.0, 0.0, 0.0])  # Initial weights (w0, w1, w2)\n",
    "\n",
    "# Set the learning rate and the number of epochs\n",
    "eta = 0.1  # Learning rate\n",
    "epochs = 10  # Number of epochs\n",
    "\n",
    "# Initialize a list to store the weight values for each epoch\n",
    "weights_history = []\n",
    "\n",
    "# Perceptron training with gradient descent\n",
    "for epoch in range(epochs):\n",
    "    # Initialize the total error for the epoch\n",
    "    epoch_error = 0\n",
    "\n",
    "    # Iterate through each training example\n",
    "    for i in range(X_bias.shape[0]):\n",
    "        # Calculate the dot product and make a prediction using the step function\n",
    "        y_pred = 1 if np.dot(w, X_bias[i]) >= 0 else -1\n",
    "\n",
    "        # If the prediction is incorrect, update the weights\n",
    "        if y[i] != y_pred:\n",
    "            w += eta * (y[i] - y_pred) * X_bias[i]\n",
    "            epoch_error += 1\n",
    "\n",
    "    # Save the weight vector for this epoch\n",
    "    weights_history.append(w.copy())\n",
    "\n",
    "    # Optionally print the weights at each epoch (can be commented out if not needed)\n",
    "    print(f\"Epoch {epoch+1}: Weights: {w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Due to it, we define the decision boundary equation as follows:\n",
    "x1_final = np.linspace(min(X[:, 0]) - 1, max(X[:, 0]) + 1, 100)\n",
    "x2_final = -w[1] * x1_final - w[0]  # Calculate x2 using the line equation\n",
    "\n",
    "# The previously defined plot:\n",
    "for i, point in enumerate(X):\n",
    "    plt.annotate(f'({point[0]}, {point[1]})', (x1[i], x2[i]), textcoords=\"offset points\", xytext=(0,4), ha='center')\n",
    "    if y[i] == 1:\n",
    "        plt.scatter(x1[i], x2[i], color='red', s=150, marker='+')\n",
    "    else:\n",
    "        plt.scatter(x1[i], x2[i], color='blue', s=50, marker='o')\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.plot(x1_final, x2_final, label='Decision Boundary', color='black', linestyle='--')\n",
    "\n",
    "# Add labels and title\n",
    "plt.title('Cartesian Plane Representation')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Classification\n",
    "\n",
    "**By using the online simulator https://playground.tensorflow.org answer the following questions (use 20% of training data, 0 noise, sigmoid activation function, no regularisation, and batch size equal to 10).**\n",
    "\n",
    "1. **Using x1 and x2 as inputs, which of the datasets can be properly classified with one hidden layer. Why?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that the <u>Exclusive or</u>, <u>Circle</u> and <u>Gaussian</u> data sets can be properly classified with just one hiden layer.\n",
    "\n",
    "In the case of <u>Exclusive or</u>, and specially <u>Gaussian</u>, this is because they are linearly separable datasets. \n",
    "\n",
    "For the <u>Circle</u> one, this is a little more complex, but the main reason resides in the existing separation of the points of the inner and outer circle, allowing topological transformations to be carried out using the radius and the angle that the data form with, for example, the X axis, and thus managing to bring these data to a plane where they are already linear separable.\n",
    "\n",
    "In the case of <u>Spiral</u> dataset, it can not be properly classified due to its multiple turns and twists, which make it highly complex and extremely non-linear unlike the <u>Circle</u> dataset.\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **How can the first dataset be correctly classified with one hidden layer?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first dataset, <u>Circle</u>, the ideal way would be to be able to make use of x1^2 and x2^2, since a circle can be described as a linear combination of squared terms.\n",
    "\n",
    "In the case described in the previous section, the ideal would be to increase the number of neurons, since this will help reduce training and test losses.\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **For each dataset, with x1 and x2 as inputs, what is the minimal topology you can find that classifies the data with a training loss smaller than 0.15?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <u>Gaussian</u>: Due to its simplicity, it only takes 1 neuron to classify the data with the provided requirements.\n",
    "\n",
    "- <u>Exclusive or</u> and <u>Circle</u>: In these cases, taking only 3 neurons we can obtain a classification that meets the requirements of the statement.\n",
    "\n",
    "- <u>Spiral</u>: As we previously commented, this dataset can not be properly classified with just one hidden layer. Performing several tests with 8 neurons, the maximum allowed by the provided web page, we can see that the training loss can be less than 0.17, but it can hardly be less than 0.15."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Find the topology to learn the final classification (the spirals) with the minimum possible inputs. Attach a screenshot of the condition and the final states.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Hopfield model\n",
    "\n",
    "**One simple realisation of the Hopfield model would be a lattice consisting in only four spins.**\n",
    "\n",
    "1. **Calculate the weights and thresholds to store the following pattern:**\n",
    "\n",
    "blue orange  \n",
    "orange blue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Defining the pattern to store\n",
    "\n",
    "# In first place, let us mark the spins are: \n",
    "#\n",
    "# blue = 1\n",
    "# orange = -1\n",
    "#\n",
    "# This way, the provided patern can be written as:\n",
    "#\n",
    "#  1  -1\n",
    "# -1   1\n",
    "\n",
    "# Writting the pattern as a vector taking into account the spins will provide us with the following array:\n",
    "pattern = np.array([1, -1, -1, 1])\n",
    "\n",
    "# where we have the following correspondence:\n",
    "#\n",
    "#\n",
    "#  1  -1     (1   2)\n",
    "# -1   1     (3   4)\n",
    "\n",
    "# To calculate the weight matrix, it is important to notice we are storing just one pattern with four spins.\n",
    "# For this reason, in the formula to calculate the weight we have P=1, N=4.\n",
    "#\n",
    "# So, in this case, w_ij = 1/4 * Pi * Pj. \n",
    "# \n",
    "# To be more specific, we can perform an outer product between the pattern and itself and divide the result by 4.\n",
    "weight_matrix = 1/4 * np.outer(pattern, pattern)\n",
    "\n",
    "# Since there are no self-connections, w_ii must be set to 0, i.e, in the weight matrix we have calcaulated\n",
    "# we should set the diagonal elements to 0 (no self-connections)\n",
    "np.fill_diagonal(weight_matrix, 0)\n",
    "\n",
    "# Display the weight matrix\n",
    "print(\"Weight matrix (W):\")\n",
    "print(weight_matrix)\n",
    "\n",
    "# Calculating the threshold:\n",
    "#\n",
    "# As we have studied, the threshold is the sum of the weights of the neurons connected to the neuron i.\n",
    "# So: \n",
    "\n",
    "# Initialize an empty list to store the thresholds\n",
    "thresholds = []\n",
    "\n",
    "# Calculate the threshold for each neuron\n",
    "for i in range(4): \n",
    "    threshold_i = 1/2 * np.sum(weight_matrix[i])\n",
    "    thresholds.append(threshold_i)  # Append the threshold to the list\n",
    "\n",
    "# To convert the list to as an array  in order to print it:\n",
    "thresholds = np.array(thresholds)\n",
    "print(\"Thresholds for all neurons:\", thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Calculate the evolution of the system until it reaches a steady state if you start with the following pattern (use asynchronous updating of the spins, T=0).**\n",
    "\n",
    "blue orange  \n",
    "blue blue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us start by defining the initial state of the network as the pattern we want to store.\n",
    "# \n",
    "# Considering the spins are:\n",
    "# blue = 1\n",
    "# orange = -1\n",
    "#\n",
    "# the provided patern can be written as:\n",
    "#\n",
    "#  1  -1\n",
    "# 1   1\n",
    "# \n",
    "# This way, the initial state of the network can be written as:\n",
    "initial_state = np.array([1, -1, 1, 1])\n",
    "\n",
    "\n",
    "# Define the update rule for the Hopfield network\n",
    "def update_state(state, weight_matrix):\n",
    "    new_state = state.copy()\n",
    "    \n",
    "    for i in range(4):\n",
    "        input_sum = np.dot(weight_matrix[i], new_state) - thresholds[i]\n",
    "        new_state[i] = 1 if input_sum > 0 else -1\n",
    "    \n",
    "    return new_state\n",
    "\n",
    "# Define a function to evolve the Hopfield network until it reaches a steady state\n",
    "def evolve_system(initial_state, weight_matrix, max_iterations=100):\n",
    "    state = initial_state.copy()\n",
    "    iteration = 0\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        new_state = update_state(state, weight_matrix)\n",
    "        if np.array_equal(state, new_state):\n",
    "            break\n",
    "        \n",
    "        state = new_state\n",
    "        iteration += 1\n",
    "    \n",
    "    return state\n",
    "\n",
    "# Evolve the system\n",
    "final_state = evolve_system(initial_state, weight_matrix)\n",
    "\n",
    "# Display the result\n",
    "print(\"\\nInitial state:\")\n",
    "print(initial_state)\n",
    "\n",
    "print(\"\\nFinal steady state:\")\n",
    "print(final_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is only to show some changes in the code from the GitHub report\n",
    "\n",
    "print(\"This is a test to show the changes in the code from my GitHub report\")\n",
    "\n",
    "import pandas as pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TestEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
